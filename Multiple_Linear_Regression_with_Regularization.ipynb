{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_WYgBy_zmJE"
   },
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "This tutorial demonstrate implementation of multiple linear regression. \n",
    "\n",
    "The key learnings of this tutorial are as follows:\n",
    "\n",
    "1. Modeling Linear regression\n",
    "            - Key learnings\n",
    "                    * loading data set\n",
    "                    * loading libraries from scikit learn\n",
    "                    * creating training and test set enviornment\n",
    "                    * implement linear regression model\n",
    "                    * evaluate linear regression model\n",
    "                    * printing linear regression model in form of equation\n",
    "                    * analysing results\n",
    "                    \n",
    "2.  Applying Hypothesis testing\n",
    "            - Key learnings\n",
    "                    * applying Hypothesis testing\n",
    "                    * analysing results\n",
    "\n",
    "3. Overcoming Collinearity, model overfitting and complexity using Regularization    \n",
    "            - Key learnings\n",
    "                    * understanding effect of Collinearity on linear regression model\n",
    "                    * analysing correlation among attributes\n",
    "                    * practical understanding on output of linear regression model in\n",
    "                      presence of correlated festures\n",
    "                    * implement, analyse Ridge regularization to avoid  collinearity,    \n",
    "                      model overfitting and model complexity\n",
    "                    * implement, analyse Lasso regularization to avoid  collinearity,    \n",
    "                      model overfitting and model complexity\n",
    "                    * discovering relevant features using Lasso model \n",
    "                    * implement, analyse Elasticnet regularization to avoid collinearity, model overfitting and model complexity\n",
    "                    * Analysing results of regularization\n",
    "                    * comparing results of regularization with linear regression model\n",
    "               \n",
    "4. Hyperparamter tuning via cross validation                     \n",
    "            - Key learnings\n",
    "                    * applying cross validation\n",
    "                    * tunning parameters of regularization techniques using cros  \n",
    "                      validation\n",
    " \n",
    "The data set used for demonstration is Moneyball which can downloaded form https://www.kaggle.com/wduckett/moneyball-mlb-stats-19622012/data . The data has been gathered from baseball-reference.com. It contains following features:\n",
    "\n",
    "1. RA: runs allowed\n",
    "2. RS:  runs scored\n",
    "3. OBP: On Base Percentage\n",
    "4. SLG: Slugging Percentage\n",
    "5. BA: Batting Average\n",
    "6. OOBP: opponent’s OBP\n",
    "7. OSLG: opponent’s SLG\n",
    "8. W:  wins in that season\n",
    "\n",
    "The features from 1-7 are used as indicator variables to predict the outcome W(i.e., wins in season). \n",
    "\n",
    "The step by step practical learning on implementing and analysing multiple linear regression to predict W is demonstrated below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FpW-nH8dzmJK"
   },
   "source": [
    "# 1. Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9ixQpzSnzmJK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd # importing pandas\n",
    "import numpy as np  # importing mumpy\n",
    "from sklearn import linear_model   # imports linear_model from scikit learn\n",
    "from sklearn import metrics # for model evaluation\n",
    "from sklearn.model_selection import train_test_split # using scikit learn for hold-out\n",
    "import matplotlib.pyplot as plt # for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ys1WGZoXzmJM"
   },
   "source": [
    "# 2. Loading data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "brSW8IDZzmJM"
   },
   "outputs": [],
   "source": [
    "# Loading data set from local machine.\n",
    "df =pd.read_csv('baseball.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>League</th>\n",
       "      <th>Year</th>\n",
       "      <th>RS</th>\n",
       "      <th>RA</th>\n",
       "      <th>W</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>BA</th>\n",
       "      <th>Playoffs</th>\n",
       "      <th>RankSeason</th>\n",
       "      <th>RankPlayoffs</th>\n",
       "      <th>G</th>\n",
       "      <th>OOBP</th>\n",
       "      <th>OSLG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARI</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>734</td>\n",
       "      <td>688</td>\n",
       "      <td>81</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>700</td>\n",
       "      <td>600</td>\n",
       "      <td>94</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.247</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>2012</td>\n",
       "      <td>712</td>\n",
       "      <td>705</td>\n",
       "      <td>93</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.247</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOS</td>\n",
       "      <td>AL</td>\n",
       "      <td>2012</td>\n",
       "      <td>734</td>\n",
       "      <td>806</td>\n",
       "      <td>69</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHC</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>613</td>\n",
       "      <td>759</td>\n",
       "      <td>61</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Team League  Year   RS   RA   W    OBP    SLG     BA  Playoffs  RankSeason  \\\n",
       "0  ARI     NL  2012  734  688  81  0.328  0.418  0.259         0         NaN   \n",
       "1  ATL     NL  2012  700  600  94  0.320  0.389  0.247         1         4.0   \n",
       "2  BAL     AL  2012  712  705  93  0.311  0.417  0.247         1         5.0   \n",
       "3  BOS     AL  2012  734  806  69  0.315  0.415  0.260         0         NaN   \n",
       "4  CHC     NL  2012  613  759  61  0.302  0.378  0.240         0         NaN   \n",
       "\n",
       "   RankPlayoffs    G   OOBP   OSLG  \n",
       "0           NaN  162  0.317  0.415  \n",
       "1           5.0  162  0.306  0.378  \n",
       "2           4.0  162  0.315  0.403  \n",
       "3           NaN  162  0.331  0.428  \n",
       "4           NaN  162  0.335  0.424  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RS</th>\n",
       "      <th>RA</th>\n",
       "      <th>W</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>BA</th>\n",
       "      <th>OOBP</th>\n",
       "      <th>OSLG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>734</td>\n",
       "      <td>688</td>\n",
       "      <td>81</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>700</td>\n",
       "      <td>600</td>\n",
       "      <td>94</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>712</td>\n",
       "      <td>705</td>\n",
       "      <td>93</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>734</td>\n",
       "      <td>806</td>\n",
       "      <td>69</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>613</td>\n",
       "      <td>759</td>\n",
       "      <td>61</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RS   RA   W    OBP    SLG     BA   OOBP   OSLG\n",
       "0  734  688  81  0.328  0.418  0.259  0.317  0.415\n",
       "1  700  600  94  0.320  0.389  0.247  0.306  0.378\n",
       "2  712  705  93  0.311  0.417  0.247  0.315  0.403\n",
       "3  734  806  69  0.315  0.415  0.260  0.331  0.428\n",
       "4  613  759  61  0.302  0.378  0.240  0.335  0.424"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=df.iloc[:,[3,4,5,6,7,8,13,14]]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RS        0\n",
       "RA        0\n",
       "W         0\n",
       "OBP       0\n",
       "SLG       0\n",
       "BA        0\n",
       "OOBP    812\n",
       "OSLG    812\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DIVYA CHITRANSH\\AppData\\Local\\Temp\\ipykernel_26940\\175157634.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['OOBP'].fillna(dataset['OOBP'].mean(),inplace=True)\n",
      "C:\\Users\\DIVYA CHITRANSH\\AppData\\Local\\Temp\\ipykernel_26940\\175157634.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['OSLG'].fillna(dataset['OSLG'].mean(),inplace=True)\n"
     ]
    }
   ],
   "source": [
    "dataset['OOBP'].fillna(dataset['OOBP'].mean(),inplace=True)\n",
    "dataset['OSLG'].fillna(dataset['OSLG'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['OOBP'].isnull().sum()\n",
    "dataset['OSLG'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBXdnyYjzmJM"
   },
   "source": [
    "## 3. Applying Hold-out method to create Train and Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OrHGeRwBzmJM"
   },
   "outputs": [],
   "source": [
    "# My_data contains all data points from My_data set from from first feature to 6th feature(indicator features)\n",
    "My_data = dataset.iloc[:,0:7] \n",
    "\n",
    "# My_target contains class information which is 7th feature in the data set of \n",
    "\n",
    "My_data_target=dataset.iloc[:,7]\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(My_data, My_data_target, test_size=0.7, random_state=10)\n",
    "\n",
    "\n",
    "#print(My_data.head())\n",
    "\n",
    "#print(My_data_target.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0U7QAkDtzmJN"
   },
   "source": [
    "## 4.  Building Multiple Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "mfx9YG_JzmJN",
    "outputId": "cbf26814-fdc4-42b0-ecc2-1c586e7df2a5"
   },
   "outputs": [],
   "source": [
    "#Create a Mulitple Linear Regression model.\n",
    "\n",
    "LR_model = linear_model.LinearRegression()\n",
    "\n",
    "#Train the model using the training sets\n",
    "\n",
    "LRfitted = LR_model.fit(X_train, Y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FnAqGzAuzmJO"
   },
   "source": [
    "## 4.1 Understanding the learnt Multiple Linear Regression model\n",
    "\n",
    "1. Getting the intercept \n",
    "2. Getting the coefficients/weights \n",
    "3. Printing the  Multiple Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DA2smcXnzmJO",
    "outputId": "c8b48d4e-022e-4b65-9335-a51bb558eff3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intercept of the model :  -0.02133966037975049\n",
      "\n",
      "\n",
      "The coefficients learned against each feature present in the data set \n",
      "\n",
      "  Feature_name  Coefficients\n",
      "0           RS      0.000004\n",
      "1           RA      0.000032\n",
      "2            W      0.000115\n",
      "3          OBP     -0.121359\n",
      "4          SLG     -0.023418\n",
      "5           BA      0.088167\n",
      "6         OOBP      1.301133\n",
      "\n",
      "\n",
      "The linear regression model \n",
      "\n",
      "W = -0.02 +  RA X 0.0 + OBP X 0.0 + SLG X 0.0 + BA X -0.12 + Playoff X -0.02 + RD X 0.09 + W X 1.3\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing the intercept of the model learned\n",
    "\n",
    "print(\"The intercept of the model : \", LRfitted.intercept_)\n",
    "\n",
    "# printing the coefficients of the model learned against features present in the data set\n",
    "print(\"\\n\")\n",
    "Feature_names = list(My_data.columns.values)\n",
    "table_coeff= pd.DataFrame({'Feature_name':Feature_names , 'Coefficients': LRfitted.coef_})  \n",
    "print(\"The coefficients learned against each feature present in the data set \\n\")\n",
    "print(table_coeff)\n",
    "\n",
    "\n",
    "\n",
    "# printing the Linear regression model\n",
    "print(\"\\n\")\n",
    "print(\"The linear regression model \\n\")\n",
    "\n",
    "print(\"W =\"  ,round(LRfitted.intercept_,2), \"+\", \" RA\" \" X\", round(LRfitted.coef_[0],2)\n",
    "     , \"+ OBP\" \" X\"  ,round(LRfitted.coef_[1],2) , \"+ SLG\" \" X\"  ,round(LRfitted.coef_[2],2)\n",
    "    , \"+ BA\" \" X\"  ,round(LRfitted.coef_[3],2) , \"+ Playoff\" \" X\"  ,round(LRfitted.coef_[4],2)\n",
    "     , \"+ RD\" \" X\"  ,round(LRfitted.coef_[5],2), \"+ W\" \" X\"  ,round(LRfitted.coef_[6],2)\n",
    "     )\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3LEB8fTzmJO"
   },
   "source": [
    "\n",
    "## 5.  Hypothesis Testing\n",
    "\n",
    "This test helps to find the importance of variables( significance) with respect to the hypothesis. To do this, we need to calculate the p value for each variable and if it is less than the desired cutoff( 0.05 is the general cut off for 95% significance) then we can say with confidence that a variable is significant. We can calculate the p-value using another library called ‘statsmodels’.<br>\n",
    "\n",
    "The ordinary least squares (OLS) algorithm is a method for estimating the parameters of a linear regression model. The OLS algorithm aims to find the values of the linear regression model's parameters (i.e., the coefficients) that minimize the sum of the squared residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vz_8Iz3UzmJP",
    "outputId": "76b85bca-d7e3-4a42-9d4f-29aaf6ebdf0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RS      0.39\n",
      "RA      0.02\n",
      "W       0.42\n",
      "OBP     0.03\n",
      "SLG     0.32\n",
      "BA      0.21\n",
      "OOBP    0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "model = sm.OLS(Y_train, X_train)\n",
    "\n",
    "Statsmodel = model.fit()\n",
    "print(round(Statsmodel.pvalues,2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vl8L_zpHzmJP"
   },
   "source": [
    "The hypothesis testing reveals that all features other than BA  are statically significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBN4NeW_zmJP"
   },
   "source": [
    "## 5. Apply Model to the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qf-nJtX8zmJP"
   },
   "outputs": [],
   "source": [
    "Prediction_test = LRfitted.predict(X_test)\n",
    "Prediction_train = LRfitted.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvmUsK4IzmJP"
   },
   "source": [
    "## 6. Evaluate Model Performance on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "M8etmjowzmJQ",
    "outputId": "e4c677e9-2039-4dc7-b1c3-664558c0548f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficients for each indicator feature in data set are\n",
      "        Actual  Predicted\n",
      "123   0.390000   0.405957\n",
      "691   0.419743   0.420124\n",
      "1130  0.419743   0.418473\n",
      "778   0.419743   0.422944\n",
      "716   0.419743   0.420857\n",
      "...        ...        ...\n",
      "14    0.399000   0.412673\n",
      "214   0.407000   0.410242\n",
      "893   0.419743   0.421725\n",
      "327   0.463000   0.456414\n",
      "160   0.442000   0.464139\n",
      "\n",
      "[863 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Predicted values')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Predict the response on the test data set\n",
    "\n",
    "print(\"The coefficients for each indicator feature in data set are\")\n",
    "\n",
    "Performance= pd.DataFrame({'Actual':Y_test, 'Predicted': Prediction_test})  \n",
    "\n",
    "print(Performance)\n",
    "\n",
    "plt.scatter(Y_test, Prediction_test,  color='blue')\n",
    "\n",
    "plt.title('Relation between true vs. predicted values')\n",
    "plt.xlabel('Actual values')\n",
    "plt.ylabel('Predicted values')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7K54im0zmJQ"
   },
   "source": [
    "The output in the table details the actual and predicted values by the model. It is observed from the entries that the model learnt is very close to the actual values. The same is demonstrated by the figure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7h4T0z2czmJQ"
   },
   "source": [
    "## 7. Evaluating the Performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "0ulNLx-lzmJQ",
    "outputId": "48b13c9d-c857-46ba-c6f6-3893c92ef87c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute Error: 0.0\n",
      "\n",
      "\n",
      "Mean squared Error: 0.0\n",
      "\n",
      "\n",
      "R2 score: 71.32 %\n"
     ]
    }
   ],
   "source": [
    "# summarize the performance of the model using MAE, MSE and Rsquare\n",
    "\n",
    "print(\"Mean absolute Error:\", round(metrics.mean_absolute_error(Y_test, Prediction_test),2))\n",
    "print(\"\\n\")\n",
    "print(\"Mean squared Error:\", round(metrics.mean_squared_error(Y_test, Prediction_test),2))\n",
    "print(\"\\n\")\n",
    "print(\"R2 score:\", round(metrics.r2_score(Y_test, Prediction_test),4)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WbIVn67zmJR"
   },
   "source": [
    "The low MAE, MSE and high R2 score is 88.32% indicates a good model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbo2o0zJzmJR"
   },
   "source": [
    "## 8.  Overcoming  Model overfitting, Collinearity and Model complexity using Regularization\n",
    "\n",
    "In general a good model is the one that just not fit good to the sample of data set provided but, also to the any new sample of data set. Overfitting is a situation where models fits excellent on the training data set but, fails to produce the same result on the testing data set. Overfitting is a common issue in supervised learning and shall be avoided. Other most common issue in multiple linear regression is model complexity where, the weights learnt by the model are heavy. The aim is to produce less complex model for easy understanding and analysing than producing complex models difficult to interpret. The model complexity increases with presence of collinearity in features present in the data set. Collinearity indicates high correlation amnong indicator features. To produce model that does not overfit and is less complex in nature, the collinearity has to handled. \n",
    "\n",
    "The practical demonstration below details the effect of collinearity and overfitting issues and methods to overcome them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmHE9GuUzmJR"
   },
   "source": [
    "### 8.1 Generating Correlation matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "TkP_Yy0RzmJR",
    "outputId": "75d657f0-894f-4c73-a975-ea3f26ee5443"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a3643_row0_col0, #T_a3643_row1_col1, #T_a3643_row2_col2, #T_a3643_row3_col3, #T_a3643_row4_col4, #T_a3643_row5_col5, #T_a3643_row6_col6, #T_a3643_row7_col7 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3643_row0_col1 {\n",
       "  background-color: #f1ccb8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3643_row0_col2 {\n",
       "  background-color: #f7b396;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3643_row0_col3, #T_a3643_row3_col0 {\n",
       "  background-color: #d85646;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3643_row0_col4, #T_a3643_row4_col0 {\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3643_row0_col5 {\n",
       "  background-color: #ec8165;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3643_row0_col6 {\n",
       "  background-color: #a7c5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3643_row0_col7 {\n",
       "  background-color: #a9c6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3643_row1_col0 {\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3643_row1_col2, #T_a3643_row2_col1, #T_a3643_row2_col6, #T_a3643_row2_col7, #T_a3643_row6_col0, #T_a3643_row6_col3, #T_a3643_row6_col4, #T_a3643_row6_col5 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3643_row1_col3 {\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3643_row1_col4 {\n",
       "  background-color: #bfd3f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3643_row1_col5 {\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3643_row1_col6 {\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3643_row1_col7 {\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3643_row2_col0 {\n",
       "  background-color: #d6dce4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3643_row2_col3 {\n",
       "  background-color: #cedaeb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3643_row2_col4 {\n",
       "  background-color: #b2ccfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3643_row2_col5, #T_a3643_row5_col6 {\n",
       "  background-color: #aec9fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3643_row3_col1 {\n",
       "  background-color: #ebd3c6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3643_row3_col2 {\n",
       "  background-color: #f7b99e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3643_row3_col4, #T_a3643_row4_col3, #T_a3643_row5_col4 {\n",
       "  background-color: #f18f71;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3643_row3_col5 {\n",
       "  background-color: #e7745b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3643_row3_col6, #T_a3643_row4_col6, #T_a3643_row4_col7 {\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3643_row3_col7 {\n",
       "  background-color: #a3c2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3643_row4_col1 {\n",
       "  background-color: #f5c2aa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3643_row4_col2 {\n",
       "  background-color: #f3c8b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3643_row4_col5 {\n",
       "  background-color: #f29274;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3643_row5_col0 {\n",
       "  background-color: #eb7d62;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3643_row5_col1 {\n",
       "  background-color: #ecd3c5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3643_row5_col2 {\n",
       "  background-color: #f3c7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3643_row5_col3 {\n",
       "  background-color: #e57058;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3643_row5_col7 {\n",
       "  background-color: #adc9fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3643_row6_col1, #T_a3643_row7_col1 {\n",
       "  background-color: #f7b599;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3643_row6_col2 {\n",
       "  background-color: #5a78e4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3643_row6_col7 {\n",
       "  background-color: #de614d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3643_row7_col0, #T_a3643_row7_col4 {\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3643_row7_col2 {\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3643_row7_col3 {\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3643_row7_col5 {\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3643_row7_col6 {\n",
       "  background-color: #dd5f4b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a3643\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a3643_level0_col0\" class=\"col_heading level0 col0\" >RS</th>\n",
       "      <th id=\"T_a3643_level0_col1\" class=\"col_heading level0 col1\" >RA</th>\n",
       "      <th id=\"T_a3643_level0_col2\" class=\"col_heading level0 col2\" >W</th>\n",
       "      <th id=\"T_a3643_level0_col3\" class=\"col_heading level0 col3\" >OBP</th>\n",
       "      <th id=\"T_a3643_level0_col4\" class=\"col_heading level0 col4\" >SLG</th>\n",
       "      <th id=\"T_a3643_level0_col5\" class=\"col_heading level0 col5\" >BA</th>\n",
       "      <th id=\"T_a3643_level0_col6\" class=\"col_heading level0 col6\" >OOBP</th>\n",
       "      <th id=\"T_a3643_level0_col7\" class=\"col_heading level0 col7\" >OSLG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a3643_level0_row0\" class=\"row_heading level0 row0\" >RS</th>\n",
       "      <td id=\"T_a3643_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_a3643_row0_col1\" class=\"data row0 col1\" >0.380139</td>\n",
       "      <td id=\"T_a3643_row0_col2\" class=\"data row0 col2\" >0.511745</td>\n",
       "      <td id=\"T_a3643_row0_col3\" class=\"data row0 col3\" >0.900492</td>\n",
       "      <td id=\"T_a3643_row0_col4\" class=\"data row0 col4\" >0.918740</td>\n",
       "      <td id=\"T_a3643_row0_col5\" class=\"data row0 col5\" >0.827000</td>\n",
       "      <td id=\"T_a3643_row0_col6\" class=\"data row0 col6\" >0.071329</td>\n",
       "      <td id=\"T_a3643_row0_col7\" class=\"data row0 col7\" >0.102976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3643_level0_row1\" class=\"row_heading level0 row1\" >RA</th>\n",
       "      <td id=\"T_a3643_row1_col0\" class=\"data row1 col0\" >0.380139</td>\n",
       "      <td id=\"T_a3643_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_a3643_row1_col2\" class=\"data row1 col2\" >-0.532394</td>\n",
       "      <td id=\"T_a3643_row1_col3\" class=\"data row1 col3\" >0.326360</td>\n",
       "      <td id=\"T_a3643_row1_col4\" class=\"data row1 col4\" >0.436527</td>\n",
       "      <td id=\"T_a3643_row1_col5\" class=\"data row1 col5\" >0.330764</td>\n",
       "      <td id=\"T_a3643_row1_col6\" class=\"data row1 col6\" >0.500050</td>\n",
       "      <td id=\"T_a3643_row1_col7\" class=\"data row1 col7\" >0.499487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3643_level0_row2\" class=\"row_heading level0 row2\" >W</th>\n",
       "      <td id=\"T_a3643_row2_col0\" class=\"data row2 col0\" >0.511745</td>\n",
       "      <td id=\"T_a3643_row2_col1\" class=\"data row2 col1\" >-0.532394</td>\n",
       "      <td id=\"T_a3643_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "      <td id=\"T_a3643_row2_col3\" class=\"data row2 col3\" >0.481836</td>\n",
       "      <td id=\"T_a3643_row2_col4\" class=\"data row2 col4\" >0.401496</td>\n",
       "      <td id=\"T_a3643_row2_col5\" class=\"data row2 col5\" >0.408716</td>\n",
       "      <td id=\"T_a3643_row2_col6\" class=\"data row2 col6\" >-0.376013</td>\n",
       "      <td id=\"T_a3643_row2_col7\" class=\"data row2 col7\" >-0.336993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3643_level0_row3\" class=\"row_heading level0 row3\" >OBP</th>\n",
       "      <td id=\"T_a3643_row3_col0\" class=\"data row3 col0\" >0.900492</td>\n",
       "      <td id=\"T_a3643_row3_col1\" class=\"data row3 col1\" >0.326360</td>\n",
       "      <td id=\"T_a3643_row3_col2\" class=\"data row3 col2\" >0.481836</td>\n",
       "      <td id=\"T_a3643_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "      <td id=\"T_a3643_row3_col4\" class=\"data row3 col4\" >0.790910</td>\n",
       "      <td id=\"T_a3643_row3_col5\" class=\"data row3 col5\" >0.851958</td>\n",
       "      <td id=\"T_a3643_row3_col6\" class=\"data row3 col6\" >0.065499</td>\n",
       "      <td id=\"T_a3643_row3_col7\" class=\"data row3 col7\" >0.083472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3643_level0_row4\" class=\"row_heading level0 row4\" >SLG</th>\n",
       "      <td id=\"T_a3643_row4_col0\" class=\"data row4 col0\" >0.918740</td>\n",
       "      <td id=\"T_a3643_row4_col1\" class=\"data row4 col1\" >0.436527</td>\n",
       "      <td id=\"T_a3643_row4_col2\" class=\"data row4 col2\" >0.401496</td>\n",
       "      <td id=\"T_a3643_row4_col3\" class=\"data row4 col3\" >0.790910</td>\n",
       "      <td id=\"T_a3643_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "      <td id=\"T_a3643_row4_col5\" class=\"data row4 col5\" >0.790481</td>\n",
       "      <td id=\"T_a3643_row4_col6\" class=\"data row4 col6\" >0.065848</td>\n",
       "      <td id=\"T_a3643_row4_col7\" class=\"data row4 col7\" >0.096316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3643_level0_row5\" class=\"row_heading level0 row5\" >BA</th>\n",
       "      <td id=\"T_a3643_row5_col0\" class=\"data row5 col0\" >0.827000</td>\n",
       "      <td id=\"T_a3643_row5_col1\" class=\"data row5 col1\" >0.330764</td>\n",
       "      <td id=\"T_a3643_row5_col2\" class=\"data row5 col2\" >0.408716</td>\n",
       "      <td id=\"T_a3643_row5_col3\" class=\"data row5 col3\" >0.851958</td>\n",
       "      <td id=\"T_a3643_row5_col4\" class=\"data row5 col4\" >0.790481</td>\n",
       "      <td id=\"T_a3643_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
       "      <td id=\"T_a3643_row5_col6\" class=\"data row5 col6\" >0.097967</td>\n",
       "      <td id=\"T_a3643_row5_col7\" class=\"data row5 col7\" >0.119277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3643_level0_row6\" class=\"row_heading level0 row6\" >OOBP</th>\n",
       "      <td id=\"T_a3643_row6_col0\" class=\"data row6 col0\" >0.071329</td>\n",
       "      <td id=\"T_a3643_row6_col1\" class=\"data row6 col1\" >0.500050</td>\n",
       "      <td id=\"T_a3643_row6_col2\" class=\"data row6 col2\" >-0.376013</td>\n",
       "      <td id=\"T_a3643_row6_col3\" class=\"data row6 col3\" >0.065499</td>\n",
       "      <td id=\"T_a3643_row6_col4\" class=\"data row6 col4\" >0.065848</td>\n",
       "      <td id=\"T_a3643_row6_col5\" class=\"data row6 col5\" >0.097967</td>\n",
       "      <td id=\"T_a3643_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
       "      <td id=\"T_a3643_row6_col7\" class=\"data row6 col7\" >0.830902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3643_level0_row7\" class=\"row_heading level0 row7\" >OSLG</th>\n",
       "      <td id=\"T_a3643_row7_col0\" class=\"data row7 col0\" >0.102976</td>\n",
       "      <td id=\"T_a3643_row7_col1\" class=\"data row7 col1\" >0.499487</td>\n",
       "      <td id=\"T_a3643_row7_col2\" class=\"data row7 col2\" >-0.336993</td>\n",
       "      <td id=\"T_a3643_row7_col3\" class=\"data row7 col3\" >0.083472</td>\n",
       "      <td id=\"T_a3643_row7_col4\" class=\"data row7 col4\" >0.096316</td>\n",
       "      <td id=\"T_a3643_row7_col5\" class=\"data row7 col5\" >0.119277</td>\n",
       "      <td id=\"T_a3643_row7_col6\" class=\"data row7 col6\" >0.830902</td>\n",
       "      <td id=\"T_a3643_row7_col7\" class=\"data row7 col7\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1bbd31e87f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the corr() function generates pair wise correlation between features\n",
    "corr = dataset.corr()\n",
    "# following code is used to visually inspect the pair wise correlation\n",
    "corr.style.background_gradient(cmap='coolwarm')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W55vtlnuzmJS"
   },
   "source": [
    "As indicated by the results, R, OBP. SLG. BA are very strongly correlated. In order to understand the effect of this correlation on the output of multiple linear regression modeling, we create three different models:\n",
    "\n",
    "Model 1: having features RS and OBP\n",
    "\n",
    "Model 2: having features RS, OBP and SLG\n",
    "\n",
    "Model 3: having features RS, OBP, SLG and BA\n",
    "\n",
    "Following section creates data sets for generation of these models. \n",
    "\n",
    "## 8.2 Creating data sets using Hold -out for Generating models in presence of high  correlated features|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "pUlqJ4I6zmJS"
   },
   "outputs": [],
   "source": [
    "# creating data set for model containing RS and OBP\n",
    "\n",
    "My_data_two = dataset.iloc[:,[0,2]] \n",
    "\n",
    "My_data_two_target=dataset.iloc[:,7]\n",
    "\n",
    "\n",
    "X_train_two, X_test_two, Y_train_two, Y_test_two = train_test_split(My_data_two, My_data_two_target, test_size=0.7, random_state=10)\n",
    "\n",
    "\n",
    "# creating data set for model containing RS,  OBP, SLG\n",
    "\n",
    "My_data_three= dataset.iloc[:,[0,2,3]] \n",
    "\n",
    "My_data_three_target=dataset.iloc[:,7]\n",
    "\n",
    "\n",
    "X_train_three, X_test_three, Y_train_three, Y_test_three = train_test_split(My_data_three, My_data_three_target, test_size=0.7, random_state=10)\n",
    "\n",
    "# creating data set for model containing RS,OBP, SLG, BA\n",
    "\n",
    "My_data_four = dataset.iloc[:,[0,2, 3,4]] \n",
    "\n",
    "My_data_four_target=dataset.iloc[:,7]\n",
    "\n",
    "\n",
    "X_train_four, X_test_four, Y_train_four, Y_test_four = train_test_split(My_data_four, My_data_four_target, test_size=0.7, random_state=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KucQpN23zmJT"
   },
   "source": [
    "## 8.3 Training  the three new models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "TdF6Rn_FzmJT"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Train the model using X_train_two, Y_train_two associated with data set containing\n",
    "#features RS, OBP\n",
    "#we call the linearr regression model again and again as its fitted with one data, it will predict on the basis of its fitted curve\n",
    "\n",
    "LR_model_two = linear_model.LinearRegression()\n",
    "LRfitted_two = LR_model_two.fit(X_train_two, Y_train_two)\n",
    "\n",
    "#Train the model using X_train_three, Y_train_three associated with data set containing\n",
    "#features RS, OBP, SLG\n",
    "\n",
    "LR_model_three = linear_model.LinearRegression()\n",
    "LRfitted_three = LR_model_three.fit(X_train_three, Y_train_three)\n",
    "\n",
    "#Train the model using X_train_four, Y_train_four associated with data set containing\n",
    "#features RS, OBP, SLG, BA\n",
    "\n",
    "LR_model_four = linear_model.LinearRegression()\n",
    "LRfitted_four = LR_model_four.fit(X_train_four, Y_train_four)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZgvEpdG4zmJU"
   },
   "source": [
    "## 8.4 Predicting training and test error for different models\n",
    "\n",
    "The training and test errors gives a good indication of overfitting. High training error and low test errors is indication to model overfitting. The code below evaluate model performance on training and test set. The errors are computed using the difference between actual and predicted values by the model. To do this, we need to predict the training and testing errors using predict() function on all the models generated so far :\n",
    "\n",
    "Model 1: having features RS and OBP\n",
    "\n",
    "Model 2: having features RS, OBP and SLG\n",
    "\n",
    "Model 3: having features RS, OBP, SLG and BA\n",
    "\n",
    "Model 4: original model containing all features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "65ARmwx0zmJU"
   },
   "outputs": [],
   "source": [
    "# Predicting training and testing error on X_train_two, X_test_two \n",
    "# (model with features RS and OBP)\n",
    "\n",
    "Prediction_train_two = LRfitted_two.predict(X_train_two)\n",
    "Prediction_test_two = LRfitted_two.predict(X_test_two)\n",
    "\n",
    "\n",
    "# Predicting training and testing error on X_train_three, X_test_three \n",
    "# (model with features RS, OBP, SLG )\n",
    "\n",
    "Prediction_train_three = LRfitted_three.predict(X_train_three)\n",
    "Prediction_test_three = LRfitted_three.predict(X_test_three)\n",
    "\n",
    "# Predicting training and testing error on X_train_four, X_test_four \n",
    "# (model with features RS, OBP, SLG, BA )\n",
    "\n",
    "Prediction_train_four = LRfitted_four.predict(X_train_four)\n",
    "Prediction_test_four = LRfitted_four.predict(X_test_four)\n",
    "\n",
    "#Predicting training and testing error on X_train, X_test \n",
    "# (model with all features RS,RA, OBP, SLG, BA, Playoff, RD )\n",
    "\n",
    "Prediction_train_all = LRfitted.predict(X_train)\n",
    "Prediction_test_all = LRfitted.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCL3XmUjzmJU"
   },
   "source": [
    "## 8.5 Preparing summary of  Train, Test error, Sum of absolute weights for different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "rVcVPTZZzmJU",
    "outputId": "72062740-dae1-4e0b-db4b-206e83c0758a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Model  Train Errors  Test Errors       SAW Rsquare %\n",
      "0     RS and OBP          0.01         0.01  0.435749       ---\n",
      "1     RS,OBP,SLG          0.01         0.01  0.455684       ---\n",
      "2  RS,OBP,SLG,BA          0.01         0.01  0.596245       ---\n",
      "3   All features          0.00         0.00  1.555568     71.32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns =['Model', 'Train Errors', 'Test Errors', 'SAW', 'Rsquare %']\n",
    "######################## Summary of Model one ###########################\n",
    "# Summary of training,test error and sum of absolute Weights(SAW) for model containing \n",
    "# features RS and OBP\n",
    "\n",
    "Reg_model1 = \"RS and OBP\"\n",
    "\n",
    "Reg_model1_values = [Reg_model1, \n",
    "                 round(metrics.mean_absolute_error(Y_train_two, Prediction_train_two),2),\n",
    "                round(metrics.mean_absolute_error(Y_test_two, Prediction_test_two),2),\n",
    "              np.absolute(LRfitted_two.coef_).sum() + np.absolute(LRfitted_two.intercept_),\n",
    "                 '---'   ]\n",
    "######################## Summary of Model two ###########################\n",
    "# Summary of training,test error and sum of absolute Weights(SAW) for model containing \n",
    "# features RS ,OBP, SLG\n",
    "\n",
    "Reg_model2 = \"RS,OBP,SLG\"\n",
    "\n",
    "Reg_model2_values = [Reg_model2, \n",
    "               round(metrics.mean_absolute_error(Y_train_three, Prediction_train_three),2),\n",
    "               round(metrics.mean_absolute_error(Y_test_three, Prediction_test_three),2),\n",
    "            np.absolute(LRfitted_three.coef_).sum() +np.absolute(LRfitted_three.intercept_),\n",
    "               \"---\"     ]\n",
    "######################## Summary of Model three  ###########################\n",
    "# Summary of training,test error and sum of absolute Weights(SAW) for model containing \n",
    "# features RS ,OBP, SLG, BA\n",
    "\n",
    "Reg_model3 = \"RS,OBP,SLG,BA\"\n",
    "\n",
    "Reg_model3_values = [Reg_model3, \n",
    "                round(metrics.mean_absolute_error(Y_train_four, Prediction_train_four),2),\n",
    "                round(metrics.mean_absolute_error(Y_test_four, Prediction_test_four),2),\n",
    "             np.absolute(LRfitted_four.coef_).sum() + np.absolute(LRfitted_four.intercept_),\n",
    "                 '---'   ]\n",
    "\n",
    "\n",
    "######################## Summary of Model four  ###########################\n",
    "# Summary of training,test error and sum of absolute Weights(SAW) for model containing \n",
    "# all features\n",
    "\n",
    "Reg_model4 = \"All features\"\n",
    "\n",
    "Reg_model4_values = [Reg_model4, \n",
    "                 round(metrics.mean_absolute_error(Y_train, Prediction_train),2),\n",
    "                round(metrics.mean_absolute_error(Y_test, Prediction_test),2),\n",
    "           np.absolute( LRfitted.coef_).sum() + np.absolute(LRfitted.intercept_),\n",
    "            round(metrics.r2_score(Y_test, Prediction_test),4)*100 ]\n",
    "\n",
    "Models_summary = pd.DataFrame([Reg_model1_values, Reg_model2_values, \n",
    "                               Reg_model3_values,Reg_model4_values\n",
    "                               ],\n",
    "                              columns= columns)\n",
    "print(Models_summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLuzg8EJzmJV"
   },
   "source": [
    "As indicated by the train and test errors on all the models, overfitting does not seem to an issue. However, as the number of correlated features increases in the model, the complexity grows, as indicated by the column SAW(sum of absolute weights). \n",
    "\n",
    "The next part of this tutorial aims to produce low complex model by treating the correlated features present in the data set using Regularization. It is a technique that controls overfitting, produces less complex model with higher performance rates. There are three types of regularization:\n",
    "\n",
    "1. Ridge(L2) \n",
    "\n",
    "    - it produces low complex model\n",
    "    - reduces the collinearity\n",
    "    - not suitable for high dimensional data\n",
    "    \n",
    "2. Lasso (L1)\n",
    "    \n",
    "    - provides important features for deciding the outcome. \n",
    "    - reduces the collinearity\n",
    "    - produces low complex model\n",
    "    - suitable for high dimensional data\n",
    "    \n",
    "3. Elastic net\n",
    "\n",
    "    - combines features of both L1 and L2\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXhVSBwizmJV"
   },
   "source": [
    "## 8.5 Implementing Ridge\n",
    "\n",
    "Ridge will be implemented for on the original data set to make it less complex (by\n",
    "removing the collinearity that results in lowering the sum of absolute weights). The\n",
    "Ridge model is also evaluated for training and testing errors. The final results of Ridge application is added in the data frame containing previous results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "OWum_thrzmJV"
   },
   "outputs": [],
   "source": [
    "# Using Ridge function, create its object. Ridge is controlled by parameter alpha. It can \n",
    "#be set by the user to tune results. \n",
    "\n",
    "ridge = linear_model.Ridge(alpha =1)\n",
    "\n",
    "# Fitting ridge on data set containing all features\n",
    "ridge.fit(X_train, Y_train)\n",
    "\n",
    "# Getting prediction on train and test sets\n",
    "Ridge_pred_train = ridge.predict(X_train)\n",
    "Ridge_pred_test= ridge.predict(X_test)\n",
    "\n",
    "# preparing summary of training, test errors, sum of absolute Weights(SAW) and rsquare\n",
    "\n",
    "Reg_model_Ridge = \"Ridge on All features\"\n",
    "Ridge_values = [Reg_model_Ridge,\n",
    "        round(metrics.mean_absolute_error(Y_train, Ridge_pred_train),2),\n",
    "        round(metrics.mean_absolute_error(Y_test, Ridge_pred_test),2),\n",
    "        np.absolute(ridge.coef_).sum() +np.absolute(ridge.intercept_ ),\n",
    "         round(metrics.r2_score(Y_test, Ridge_pred_test),4)*100           ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2mM9wE4zmJW"
   },
   "source": [
    "## 8.6 Implementing Lasso Regression\n",
    "\n",
    "The following code implements LASSO on the original data set to make it less complex (by\n",
    "removing the collinearity that results in lowering the sum of absolute weights) andto find important features for the decision variable. The LASSO model is also evaluated for training and testing errors. The final results of LASSO application is added in the data frame containing previous results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "KmGrBWkuzmJW",
    "outputId": "351c2eeb-8191-4b2a-9378-0a58faefbab7"
   },
   "outputs": [],
   "source": [
    "# Loading library\n",
    "\n",
    "\n",
    "# Using lasso function, create its object. lasso is controlled by parameter alpha. It can \n",
    "#be set by the user to tune results. \n",
    "\n",
    "lasso = linear_model.Lasso(alpha =0.2)\n",
    "\n",
    "# Fitting lasso on data set containing all features\n",
    "lasso.fit(X_train, Y_train)\n",
    "\n",
    "# Getting prediction on train and test sets\n",
    "lasso_pred_train = lasso.predict(X_train)\n",
    "lasso_pred_test= lasso.predict(X_test)\n",
    "\n",
    "# preparing summary of training, test errors, sum of absolute Weights(SAW) and rsquare\n",
    "Reg_model_Lasso = \"Lasso on All features\"\n",
    "Lasso_values = [Reg_model_Lasso,\n",
    "        round(metrics.mean_absolute_error(Y_train, lasso_pred_train),2),\n",
    "        round(metrics.mean_absolute_error(Y_test, lasso_pred_test),2),\n",
    "        np.absolute(lasso.coef_).sum() +np.absolute(lasso.intercept_ ),\n",
    "         round(metrics.r2_score(Y_test, lasso_pred_test),4)*100           ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEv1PZUVzmJW"
   },
   "source": [
    "### 8.6.1 Analysing important features as resulted by LASSO regularization\n",
    "\n",
    "The key aim is to discover how many variables Lasso picked out of total list of features present in the data set ? For non relevant features, LASSO makes the coefficient equal to \n",
    "zero.  The following code find all those features where the coefficients(weights) of the \n",
    "LASSO model for features were discovered to be zero. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "O8duq3WYzmJX",
    "outputId": "63e4bc43-729c-4e7a-acb2-afc9a3d462b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Lasso picked 1 features and eliminated the other 6 variables\n",
      "\n",
      "\n",
      "List of Relevant features: \n",
      "  ['RA']\n",
      "\n",
      "\n",
      "List of Nonrelevant features: \n",
      "  ['RS', 'W', 'OBP', 'SLG', 'BA', 'OOBP']\n"
     ]
    }
   ],
   "source": [
    "# Performance of Lasso \n",
    "print(\"\\n\")\n",
    "print(\"Lasso picked \" + str(sum(lasso.coef_!= 0)) \n",
    "      + \" features and eliminated the other \" +  \n",
    "      str(sum(lasso.coef_ == 0)) + \" variables\")\n",
    "\n",
    "print(\"\\n\")\n",
    "# Printing relevant and nonrelevant features as discovered by Lasso \n",
    "Relevant_features =[]\n",
    "Nonrelevant_features =[]\n",
    "for i in range(len(dataset.columns)-1):\n",
    "    if(lasso.coef_[i]!=0):\n",
    "        Relevant_features.append(dataset.columns[i])\n",
    "    else:\n",
    "        Nonrelevant_features.append(dataset.columns[i])\n",
    "    \n",
    "print(\"List of Relevant features: \\n \", Relevant_features)\n",
    "print(\"\\n\")\n",
    "print(\"List of Nonrelevant features: \\n \", Nonrelevant_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9_eWot6zmJX"
   },
   "source": [
    "LASSO discovers features RS, RA, Playoff and RD as only relevant features. It means that\n",
    "only these features are enough to be used out of total available for model building. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GKelAaezmJY"
   },
   "source": [
    "## 8.8 Evaluating results of all models\n",
    "\n",
    "In this section we add, results of Ridge, LASSO and ElasticNet to the Pandas DataFrame created earlier for comparison of results. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "rRX4jvuWzmJY",
    "outputId": "0c6072ef-5009-4c3a-e26b-0ab05377a57e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Model  Train Errors  Test Errors       SAW Rsquare %\n",
      "0             RS and OBP          0.01         0.01  0.435749       ---\n",
      "1             RS,OBP,SLG          0.01         0.01  0.455684       ---\n",
      "2          RS,OBP,SLG,BA          0.01         0.01  0.596245       ---\n",
      "3           All features          0.00         0.00  1.555568     71.32\n",
      "4  Ridge on All features          0.01         0.01  0.407650     28.61\n",
      "5  Lasso on All features          0.01         0.01  0.385374     21.07\n"
     ]
    }
   ],
   "source": [
    "# putting summary of results in Pandas dataframe and printing it\n",
    "columns =['Model', 'Train Errors', 'Test Errors', 'SAW', 'Rsquare %']\n",
    "regularization = pd.DataFrame([ Ridge_values, Lasso_values],\n",
    "                              columns= columns)\n",
    "\n",
    "\n",
    "results = [Models_summary, regularization]\n",
    "All_models_summary= pd.concat(results, ignore_index=True)                           \n",
    "print(All_models_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0QBSSCDLzmJY"
   },
   "source": [
    "The regularization methods have significantly decreased the sum of absolute weights by keeping low training and test errors and high rsquare value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtwW_zuQzmJY"
   },
   "source": [
    "## 8.9 Generating Regression equations of all models and comparing their weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "-f2nWxZ5zmJZ",
    "outputId": "22c9b7fe-9d2d-4e9e-a95f-156d07c420e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The LR model on RS and OBP \n",
      "\n",
      "W = 0.44 +  RS X 0.0 + OBP X -0.0\n",
      "\n",
      "\n",
      "The LR model on RS,OBP, SLG \n",
      "\n",
      "W = 0.44 +  RS X 0.0 + OBP X -0.0 + SLG X -0.02\n",
      "\n",
      "\n",
      "The LR model on RS, OBP, SLG, BA \n",
      "\n",
      "W = 0.46 +  RS X 0.0 + OBP X -0.0 + SLG X -0.05 + BA X -0.08\n",
      "\n",
      "\n",
      "The LR model on RS, RA, OBP, SLG, BA, Playoff, RD \n",
      "\n",
      "W = -0.02 + RS X 0.0 + RA X 0.0 + OBP X 0.0 + SLG X -0.12 + BA X -0.02 + Playoff X 0.09 + RD X 1.3\n",
      "\n",
      "\n",
      "The Ridge model on the dataset \n",
      "\n",
      "W = 0.37 + RS X -0.0 + RA X 0.0 + OBP X -0.0 + SLG X -0.0 + BA X -0.01 + Playoff X 0.0 + RD X 0.03\n",
      "\n",
      "\n",
      "The Lasso model on the data set\n",
      "\n",
      "W = 0.37 + RS X -0.0 + RA X 0.0 + OBP X -0.0 + SLG X -0.0 + BA X -0.0 + Playoff X 0.0 + RD X 0.0\n"
     ]
    }
   ],
   "source": [
    "############ model on features RS, OBP #############\n",
    "\n",
    "LR_model_one_features_names = list(['RS', 'OBP'])\n",
    "\n",
    "LR_model_one_table_coeff= pd.DataFrame({'Feature_name':LR_model_one_features_names ,\n",
    "                                        'Coefficients': LRfitted_two.coef_})  \n",
    "\n",
    "# printing the Linear regression model\n",
    "print(\"\\n\")\n",
    "print(\"The LR model on RS and OBP \\n\")\n",
    "\n",
    "print(\"W =\"  ,round(LRfitted_two.intercept_,2), \"+\",\n",
    "      \" RS\" \" X\", round(LRfitted_two.coef_[0],2),\n",
    "     \"+ OBP\" \" X\"  ,round(LRfitted_two.coef_[1],2))\n",
    "     \n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "############ model on features RS, OBP, SLG #############\n",
    "\n",
    "LR_model_two_features_names = list(['RS', 'OBP', 'SLG'])\n",
    "\n",
    "LR_model_two_table_coeff= pd.DataFrame({'Feature_name':LR_model_two_features_names ,\n",
    "                                        'Coefficients': LRfitted_three.coef_})  \n",
    "\n",
    "\n",
    "# printing the Linear regression model\n",
    "\n",
    "print(\"The LR model on RS,OBP, SLG \\n\")\n",
    "\n",
    "print(\"W =\"  ,round(LRfitted_three.intercept_,2), \"+\",\n",
    "      \" RS\" \" X\", round(LRfitted_three.coef_[0],2),\n",
    "     \"+ OBP\" \" X\"  ,round(LRfitted_three.coef_[1],2),  \n",
    "      \"+ SLG\" \" X\"  ,round(LRfitted_three.coef_[2],2)\n",
    "     )\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "############ model on features RS, OBP, SLG, BA #############\n",
    "\n",
    "\n",
    "\n",
    "LR_model_three_features_names = list(['RS', 'OBP', 'SLG', 'RA'])\n",
    "\n",
    "LR_model_three_table_coeff= pd.DataFrame({'Feature_name':LR_model_three_features_names ,\n",
    "                                        'Coefficients': LRfitted_four.coef_})  \n",
    "\n",
    "\n",
    "# printing the Linear regression model\n",
    "\n",
    "print(\"The LR model on RS, OBP, SLG, BA \\n\")\n",
    "\n",
    "print(\"W =\"  ,round(LRfitted_four.intercept_,2), \"+\", \n",
    "      \" RS\" \" X\", round(LRfitted_four.coef_[0],2), \n",
    "     \"+ OBP\" \" X\"  ,round(LRfitted_four.coef_[1],2),  \n",
    "      \"+ SLG\" \" X\"  ,round(LRfitted_four.coef_[2],2),\n",
    "     \"+ BA\" \" X\", round(LRfitted_four.coef_[3],2)\n",
    "      )\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "############ model on features RS, OBP, SLG, BA, Playoff, RD #############\n",
    "\n",
    "\n",
    "\n",
    "LR_model_features_names = list(['RS','RA','OBP', 'SLG', 'BA', 'Playoff', 'RD'])\n",
    "\n",
    "LR_model_table_coeff= pd.DataFrame({'Feature_name':LR_model_features_names ,\n",
    "                                        'Coefficients': LRfitted.coef_})  \n",
    "\n",
    "\n",
    "# printing the Linear regression model\n",
    "\n",
    "print(\"The LR model on RS, RA, OBP, SLG, BA, Playoff, RD \\n\")\n",
    "\n",
    "print(\"W =\"  ,round(LRfitted.intercept_,2), \n",
    "      \"+ RS\" \" X\", round(LRfitted.coef_[0],2), \n",
    "      \"+ RA\" \" X\"  ,round(LRfitted.coef_[1],2),\n",
    "      \"+ OBP\" \" X\"  ,round(LRfitted.coef_[2],2), \n",
    "      \"+ SLG\" \" X\"  ,round(LRfitted.coef_[3],2),\n",
    "       \"+ BA\" \" X\", round(LRfitted.coef_[4],2),\n",
    "      \"+ Playoff\" \" X\", round(LRfitted.coef_[5],2),\n",
    "      \"+ RD\" \" X\", round(LRfitted.coef_[6],2),\n",
    "      \n",
    "\n",
    "      )\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "############ Ridge model on features RS, RA OBP, SLG, BA, Playoff, RD #############\n",
    "\n",
    "\n",
    "Ridge_Feature_names = list(My_data.columns.values)\n",
    "\n",
    "\n",
    "Ridge_table_coeff= pd.DataFrame({'Feature_name':Ridge_Feature_names , \n",
    "                                 'Coefficients': ridge.coef_})  \n",
    "\n",
    "# printing the Ridge Linear regression model\n",
    "print(\"The Ridge model on the dataset \\n\")\n",
    "\n",
    "print(\"W =\"  ,round(ridge.intercept_,2), \n",
    "      \"+ RS\" \" X\", round(ridge.coef_[0],2), \n",
    "      \"+ RA\" \" X\"  ,round(ridge.coef_[1],2),\n",
    "      \"+ OBP\" \" X\"  ,round(ridge.coef_[2],2), \n",
    "      \"+ SLG\" \" X\"  ,round(ridge.coef_[3],2),\n",
    "       \"+ BA\" \" X\", round(ridge.coef_[4],2),\n",
    "      \"+ Playoff\" \" X\", round(ridge.coef_[5],2),\n",
    "      \"+ RD\" \" X\", round(ridge.coef_[6],2),\n",
    "      \n",
    "\n",
    "      )\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "############ Lasso model on features RS, RA OBP, SLG, BA, Playoff, RD #############\n",
    "\n",
    "\n",
    "Lasso_Feature_names = list(My_data.columns.values)\n",
    "\n",
    "Lasso_table_coeff= pd.DataFrame({'Feature_name':Lasso_Feature_names , \n",
    "                                 'Coefficients': lasso.coef_})  \n",
    "\n",
    "# printing the Lasso Linear regression model\n",
    "print(\"The Lasso model on the data set\\n\")\n",
    "print(\"W =\"  ,round(ridge.intercept_,2), \n",
    "      \"+ RS\" \" X\", round(lasso.coef_[0],2), \n",
    "      \"+ RA\" \" X\"  ,round(lasso.coef_[1],2),\n",
    "      \"+ OBP\" \" X\"  ,round(lasso.coef_[2],2), \n",
    "      \"+ SLG\" \" X\"  ,round(lasso.coef_[3],2),\n",
    "       \"+ BA\" \" X\", round(lasso.coef_[4],2),\n",
    "      \"+ Playoff\" \" X\", round(lasso.coef_[5],2),\n",
    "      \"+ RD\" \" X\", round(lasso.coef_[6],2),\n",
    "      \n",
    "\n",
    "      )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHLlK3sRzmJZ"
   },
   "source": [
    "## 8.10 Visualization of Results of all models on significance of features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "3BGTUVAjzmJZ",
    "outputId": "2095bbf7-011a-41af-e4ab-a7338de5ff7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Lasso model'}>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Features_importance_model = pd.Series(LRfitted.coef_, index= X_train.columns)\n",
    "Features_importance_Ridge = pd.Series(ridge.coef_, index= X_train.columns)\n",
    "Features_importance_Lasso = pd.Series(lasso.coef_, index= X_train.columns)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10,10))\n",
    "Features_importance_model.plot(ax=axs[0,0], kind='barh', title ='LR model' )\n",
    "\n",
    "Features_importance_Ridge.plot(ax=axs[0,1], kind='barh', title ='Ridge model')\n",
    "Features_importance_Lasso.plot(ax=axs[1,0], kind='barh', title ='Lasso model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRsM84cczmJa"
   },
   "source": [
    "As discussed earlier, LASSO model not only helps in making the model less complex but, it can also be used to find important features. The most important features for the outcome variable W are Playoff, RD, RA and RS as discovered by LASSO and Elasticnet models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjo3HrkvzmJa"
   },
   "source": [
    "# 9. Hyperparameter Selection via Cross-Validation\n",
    "\n",
    "The output of regularization techniques depends on the value given to the  paramter alpha. The good choice of value of alpha can be discovered by cross-validation technique. \n",
    "\n",
    "The following codes find best alpha for Ridge and LASSO using 10 cross validation and alpha value ranging from 0.2 to 1.0. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kBIgguOzmJa"
   },
   "source": [
    "## 9.1 Tuning Hyperparameter parameter of Ridge regression using Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "8toPvZu8zmJa",
    "outputId": "3c400a1c-43a0-49e4-c129-a528c623103e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best alpha value discovered: 0.2\n"
     ]
    }
   ],
   "source": [
    "# Using RidgeCV function, create its object. RidgeCV is controlled by parameters cv and\n",
    "# alphas. Paramter cv defines number of cross validation cycles whereas, range of \n",
    "# different alpha values can be listed using alphas parameter. \n",
    "\n",
    "ridge_cv = linear_model.RidgeCV(cv =10, alphas =[0.2, 0.4,0.5,0.6,0.8,1.0])\n",
    "\n",
    "# Fitting ridge on data set containing all features\n",
    "ridge_cv.fit(X_train, Y_train)\n",
    "\n",
    "# Getting prediction on train and test sets\n",
    "Ridge_cv_pred_train = ridge_cv.predict(X_train)\n",
    "Ridge_cv_pred_test= ridge_cv.predict(X_test)\n",
    "\n",
    "# preparing summary of training, test errors, sum of absolute Weights(SAW) and rsquare\n",
    "\n",
    "Ridge_cv_model = \"RidgeCV on All features\"\n",
    "Ridge_cv_values = [Ridge_cv_model,\n",
    "        round(metrics.mean_absolute_error(Y_train, Ridge_cv_pred_train),2),\n",
    "        round(metrics.mean_absolute_error(Y_test, Ridge_cv_pred_test),2),\n",
    "        np.absolute(ridge_cv.coef_).sum() +np.absolute(ridge_cv.intercept_ ),\n",
    "         round(metrics.r2_score(Y_test,Ridge_cv_pred_test),4)*100           ]\n",
    "\n",
    "print(\"The best alpha value discovered:\" ,ridge_cv.alpha_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gpuLTeqzmJa"
   },
   "source": [
    "## 9.2  Tuning Hyperparameter parameter of Lasso regression using Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "hV-1IbAkzmJb",
    "outputId": "8ecc4f06-34e6-49d2-d169-ecaeb831c0c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best alpha value discovered: 0.2\n"
     ]
    }
   ],
   "source": [
    "# Using LassoCV function, create its object. LassoCV is controlled by parameters cv and\n",
    "# alphas. Paramter cv defines number of cross validation cycles whereas, range of \n",
    "# different alpha values can be listed using alphas parameter. \n",
    "\n",
    "lasso_cv = linear_model.LassoCV(cv =10, alphas =[0.2, 0.4,0.5,0.6,0.8,1.0])\n",
    "\n",
    "# Fitting Lasso on data set containing all features\n",
    "lasso_cv.fit(X_train, Y_train)\n",
    "\n",
    "# Getting prediction on train and test sets\n",
    "Lasso_cv_pred_train = lasso_cv.predict(X_train)\n",
    "Lasso_cv_pred_test= lasso_cv.predict(X_test)\n",
    "\n",
    "# preparing summary of training, test errors, sum of absolute Weights(SAW) and rsquare\n",
    "\n",
    "Lasso_cv_model = \"LassoCV on All features\"\n",
    "Lasso_cv_values = [Lasso_cv_model,\n",
    "        round(metrics.mean_absolute_error(Y_train, Lasso_cv_pred_train ),2),\n",
    "        round(metrics.mean_absolute_error(Y_test, Lasso_cv_pred_test),2),\n",
    "        np.absolute(lasso_cv .coef_).sum() +np.absolute(lasso_cv .intercept_ ),\n",
    "         round(metrics.r2_score(Y_test,Lasso_cv_pred_test),4)*100           ]\n",
    "\n",
    "print(\"The best alpha value discovered:\" ,lasso_cv.alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s67NMJo1zmJb"
   },
   "source": [
    "# Summary\n",
    "\n",
    "This script demonstrates  fitting Multiple linear regression models to a given dataset. Regression concepts such as  model overfitting, collinearlity, model complexity are discussed.A practical understanding on  regularization methods, called ridge and lasso regression are also presented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple-Linear-Regression-with-Regularization\n",
    "A small project addressing a regression problem explains implementation of multiple linear regression techniques, hyperparameter tuning, collinearity, model overfitting and complexity using LASSO, Ridge and Elastic net\n",
    "\n",
    "Key learnings:\n",
    "\n",
    "1.understanding effect of Collinearity on linear regression model<br>\n",
    "2.analysing correlation among attributes<br>\n",
    "3.practical understanding on output of linear regression model in presence of correlated festures 4.implement, analyse Ridge regularization to avoid collinearity,\n",
    "model overfitting and model complexity<br>\n",
    "implement, analyse Lasso regularization to avoid collinearity,\n",
    "4.model overfitting and model complexity<br>\n",
    "5.discovering relevant features using Lasso model<br>\n",
    "6.implement, analyse Elasticnet regularization to avoid collinearity , model overfitting and model complexity<br><br>\n",
    "7.Analysing results of regularization<br>\n",
    "8.comparing results of regularization with linear regression model<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
